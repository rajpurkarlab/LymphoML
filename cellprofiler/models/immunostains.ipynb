{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c385dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f062a",
   "metadata": {},
   "source": [
    "## Get Label Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919b0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA_SPLITS = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/processed/data_splits\"\n",
    "PATH_TO_CELLPROFILER_SPLITS_OUTPUT = os.path.join(PATH_TO_DATA_SPLITS, \"custom_splits/cellprofiler/stardist_patch_num=4\")\n",
    "\n",
    "PATH_TO_TRAIN = os.path.join(PATH_TO_CELLPROFILER_SPLITS_OUTPUT, \"train.csv\")\n",
    "PATH_TO_VAL = os.path.join(PATH_TO_CELLPROFILER_SPLITS_OUTPUT, \"val.csv\")\n",
    "PATH_TO_TEST = os.path.join(PATH_TO_CELLPROFILER_SPLITS_OUTPUT, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_df = pd.read_csv(PATH_TO_TRAIN)\n",
    "train_features_df[\"patient_id\"] = train_features_df[\"Image\"].apply(lambda im : im.split(\"-\")[0])\n",
    "\n",
    "print(train_features_df.shape)\n",
    "train_features_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547536fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features_df = pd.read_csv(PATH_TO_VAL)\n",
    "val_features_df[\"patient_id\"] = val_features_df[\"Image\"].apply(lambda im : im.split(\"-\")[0])\n",
    "\n",
    "print(val_features_df.shape)\n",
    "val_features_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1741b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_df = pd.read_csv(PATH_TO_TEST)\n",
    "test_features_df[\"patient_id\"] = test_features_df[\"Image\"].apply(lambda im : im.split(\"-\")[0])\n",
    "\n",
    "print(test_features_df.shape)\n",
    "test_features_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb70748",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train_features_df.columns)\n",
    "# Update this list based on the specific features.\n",
    "columns_to_remove = [\"Image\", \"patient_id\", \"tma_id\", \"label\", \"split\", \"NormalizedMoment\", \"count\",\n",
    "                     \"Unnamed\", \"nucleiObjectNumber\", \"cytoplasmObjectNumber\"]\n",
    "for column_name in columns_to_remove:\n",
    "    columns = list(filter(lambda col: not(column_name in col), columns))\n",
    "all_features = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9479e80",
   "metadata": {},
   "source": [
    "## Get Features of Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = set(list(map(lambda s : s.split(\"_\")[0], all_features)))\n",
    "feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4fbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_of_type(all_features, feature_type):\n",
    "    return list(filter(lambda s : s.split(\"_\")[0] == feature_type, all_features))\n",
    "\n",
    "features_of_type = get_features_of_type(all_features, \"nucleiLocation\")\n",
    "features_of_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a01ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_shape_features(feature_type):\n",
    "    assert(feature_type == \"nucleiAreaShape\" or feature_type == \"cytoplasmAreaShape\")\n",
    "    all_area_shape_features = get_features_of_type(all_features, feature_type)\n",
    "    # These are spatial features, so we don't include them for Section 1.1 experiments.\n",
    "    to_remove = [\"BoundingBoxMaximum\", \"BoundingBoxMinimum\", \"Center\", \"CentralMoment\", \"SpatialMoment\"]\n",
    "    area_shape_features = []\n",
    "    for feature in all_area_shape_features:\n",
    "        if feature.split(\"_\")[1] not in to_remove:\n",
    "            area_shape_features.append(feature)\n",
    "    return area_shape_features\n",
    "\n",
    "def get_location_features(feature_type):\n",
    "    assert(feature_type == \"nucleiLocation\" or feature_type == \"cytoplasmLocation\")\n",
    "    all_location_features = get_features_of_type(all_features, feature_type)\n",
    "    # These are spatial features, so we don't include them for Section 1.1 experiments.\n",
    "    to_remove = [\"Center\"]\n",
    "    location_features = []\n",
    "    for feature in all_location_features:\n",
    "        if feature.split(\"_\")[1] not in to_remove:\n",
    "            location_features.append(feature)\n",
    "    return location_features\n",
    "\n",
    "def get_nuclei_morphological_features(all_features):\n",
    "    area_shape_features = get_area_shape_features(\"nucleiAreaShape\")\n",
    "    number_features = get_features_of_type(all_features, \"nucleiNumber\")\n",
    "    return area_shape_features + number_features\n",
    "\n",
    "def get_nuclei_intensity_features(all_features):\n",
    "    area_shape_features = get_area_shape_features(\"nucleiAreaShape\")\n",
    "    number_features = get_features_of_type(all_features, \"nucleiNumber\")\n",
    "    location_features = get_location_features(\"nucleiLocation\")\n",
    "    intensity_features = get_features_of_type(all_features, \"nucleiIntensity\")\n",
    "    return area_shape_features + number_features + location_features + intensity_features\n",
    "\n",
    "def get_nuclei_cytoplasm_morphological_features(all_features):\n",
    "    n_area_shape_features = get_features_of_type(all_features, \"nucleiAreaShape\")\n",
    "    n_number_features = get_features_of_type(all_features, \"nucleiNumber\")\n",
    "    n_children_features = get_features_of_type(all_features, \"nucleiChildren\")\n",
    "    \n",
    "    c_area_shape_features = get_features_of_type(all_features, \"cytoplasmAreaShape\")\n",
    "    c_number_features = get_features_of_type(all_features, \"cytoplasmNumber\")\n",
    "    c_parent_features = get_features_of_type(all_features, \"cytoplasmParent\")\n",
    "    \n",
    "    return (n_area_shape_features + n_number_features + n_children_features + \n",
    "            c_area_shape_features + c_number_features + c_parent_features)\n",
    "\n",
    "nuclei_features = get_nuclei_morphological_features(all_features)\n",
    "nuclei_intensity_features = get_nuclei_intensity_features(all_features)\n",
    "nuclei_cyto_features = get_nuclei_cytoplasm_morphological_features(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc911694",
   "metadata": {},
   "source": [
    "## Read Additional Stains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8be9fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e25940",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RAW_DATA = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/raw\"\n",
    "PATH_TO_MASTER_KEY = os.path.join(PATH_TO_RAW_DATA, \"Guatemala Project Data vFINAL.xlsx\")\n",
    "PATH_TO_CLPA_FILE = os.path.join(PATH_TO_RAW_DATA, \"CLPA Diagnostic Bin.xlsx\")\n",
    "CASE = \"CASE\"\n",
    "WHO_DIAGNOSIS = \"2017 WHO DIAGNOSIS\"\n",
    "CLPA_DIAGNOSIS = \"CLPA Diagnostic Bin\"\n",
    "LABEL = \"label\"\n",
    "TMA_ID = \"TMA ID\"\n",
    "\n",
    "PATH_TO_DATA_SPLITS = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/processed/data_splits\"\n",
    "PATH_TO_SPLITS_OUTPUT = os.path.join(PATH_TO_DATA_SPLITS, \"custom_splits/stains\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 400)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d73e4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_set(set_index, set_name):\n",
    "    # Read the diagnoses from sheet 'set_name' in the Master Key file and store\n",
    "    # them in the dataframe.\n",
    "    df = read_excel(PATH_TO_MASTER_KEY, sheet_name=set_name,\n",
    "                    engine='openpyxl')\n",
    "    df[TMA_ID] = set_index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36d1099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sheet_names = [\"Set(1)\", \"Set(2)\", \"Set(3)\", \"Set (4)\", \"Set (5)\", \"Set (6)\", \"Set (7)\", \"Set (8)\"]\n",
    "# Create a dataframe containing the diagnoses for each patient ID in all\n",
    "# the TMAs inside the Master Key.\n",
    "ihc_df = pd.concat([get_df_from_set(set_index + 1, set_name) for set_index, set_name in enumerate(all_sheet_names)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d4319e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihc_df = ihc_df[ihc_df[CASE].str.contains(\"E0\", na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3fe21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihc_df[\"CASE\"] = ihc_df[\"CASE\"].apply(lambda case : case.replace(\" \", \"\"))\n",
    "ihc_df = ihc_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ab861",
   "metadata": {},
   "source": [
    "## Add stains to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2cd2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAIN_LIST = ['CD20', 'CD10', 'PAX5', 'EBV ISH', 'BCL1', 'BCL6', 'TIA', 'FISH - MYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d0e8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stain_to_df(df, stain):\n",
    "    stain_map = ihc_df.set_index('CASE')[stain].to_dict()\n",
    "    stain_list = []\n",
    "    for patient_id in df[\"patient_id\"]:\n",
    "        case_key = patient_id.split(\"_\")[2].replace(\" \", \"\")\n",
    "        if case_key in stain_map:\n",
    "            stain_list.append(stain_map[case_key])\n",
    "        else:\n",
    "            print(case_key)\n",
    "            stain_list.append(\"NaN\")\n",
    "    df[stain] = stain_list\n",
    "    return df\n",
    "\n",
    "def add_stains_to_df(df):\n",
    "    value_map = {\"3 (dim)\": 3, \"3(dim)\": 3, \"3 (vari)\": 3, \"3 (dim subset?)\": 3, \"3 (mod)\": 3, \"3 (variable)\": 3, \"3 (bright)\": 1,\n",
    "             \"3 (strong)\": 3, \"3 (100%)\": 3, \"3 (cyto)\": 3,\n",
    "             \"2 (dim)\": 2, \"2 (vari)\": 2,\n",
    "             \"?\": 0, \"N\": 0, \"E\": 0, \"NN\": 0, \"sprouts\": 0, float('nan') : -1}\n",
    "    for stain in STAIN_LIST:\n",
    "        df = add_stain_to_df(df, stain)\n",
    "        df[stain] = df[stain].apply(lambda value : value_map[value] if value in value_map else value)\n",
    "    return df\n",
    "\n",
    "train_features_df = add_stains_to_df(train_features_df)\n",
    "val_features_df = add_stains_to_df(val_features_df)\n",
    "test_features_df = add_stains_to_df(test_features_df)\n",
    "all_features.extend(STAIN_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5f0be17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cytoplasmParent_cells_kurtosis',\n",
       " 'cytoplasmParent_cells_iqr',\n",
       " 'cytoplasmParent_nuclei_mean',\n",
       " 'cytoplasmParent_nuclei_std',\n",
       " 'cytoplasmParent_nuclei_skew',\n",
       " 'cytoplasmParent_nuclei_kurtosis',\n",
       " 'cytoplasmParent_nuclei_iqr',\n",
       " 'CD20',\n",
       " 'CD10',\n",
       " 'PAX5',\n",
       " 'EBV ISH',\n",
       " 'BCL1',\n",
       " 'BCL6',\n",
       " 'TIA',\n",
       " 'FISH - MYC']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116a004",
   "metadata": {},
   "source": [
    "## Model Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ae70102",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "LABEL_DIST = [0.448980, 0.162065, 0.102041, 0.088836, 0.074430, 0.058824, 0.044418, 0.018007, 0.002401]\n",
    "\n",
    "label_mapping = {0 : 0, # DLBCL -> DLBCL, Agg BCL (0)\n",
    "                 1 : 1, # HL -> HL (1)\n",
    "                 2 : 0, # Agg BCL -> DLBCL, Agg BCL (0)\n",
    "                 3 : 2, # FL -> CLL, FL, MZL (2)\n",
    "                 4 : 3, # MCL -> MCL (3)\n",
    "                 5 : 2, # MZL -> CLL, FL, MZL (2)\n",
    "                 6 : 4, # TCL -> TCL (4)\n",
    "                 7 : 4, # NKTCL -> NKTCL (4)\n",
    "                 8 : 5}\n",
    "\n",
    "def group_labels(label):\n",
    "    return label_mapping[label]\n",
    "\n",
    "def get_processed_df_splits(feature_cols):\n",
    "    train_geo_features_df = train_features_df[feature_cols + [\"patient_id\", \"label\", \"count\"]].dropna().reset_index(drop=True)\n",
    "    val_geo_features_df = val_features_df[feature_cols + [\"patient_id\", \"label\", \"count\"]].dropna().reset_index(drop=True)\n",
    "    test_geo_features_df = test_features_df[feature_cols + [\"patient_id\", \"label\", \"count\"]].dropna().reset_index(drop=True)\n",
    "    \n",
    "    train_geo_features_df[\"label\"] = train_geo_features_df[\"label\"].apply(group_labels)\n",
    "    val_geo_features_df[\"label\"] = val_geo_features_df[\"label\"].apply(group_labels)\n",
    "    test_geo_features_df[\"label\"] = test_geo_features_df[\"label\"].apply(group_labels)\n",
    "    \n",
    "    return (train_geo_features_df, val_geo_features_df, test_geo_features_df)\n",
    "\n",
    "def get_splits(feature_cols, enable_dlbcl_classification=False, enable_normalization=True):\n",
    "    (train_geo_features_df, val_geo_features_df, test_geo_features_df) = get_processed_df_splits(feature_cols)\n",
    "    \n",
    "    X_train = train_geo_features_df[feature_cols].astype(np.float32)\n",
    "    y_train = train_geo_features_df[\"label\"]\n",
    "    X_val = val_geo_features_df[feature_cols].astype(np.float32)\n",
    "    y_val = val_geo_features_df[\"label\"]\n",
    "    X_test = test_geo_features_df[feature_cols].astype(np.float32)\n",
    "    y_test = test_geo_features_df[\"label\"]\n",
    "    \n",
    "    if enable_dlbcl_classification:\n",
    "        y_train = y_train.apply(lambda l : 0 if l == 0 else 1)\n",
    "        y_val = y_val.apply(lambda l : 0 if l == 0 else 1)\n",
    "        y_test = y_test.apply(lambda l : 0 if l == 0 else 1)\n",
    "    \n",
    "    if enable_normalization:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test, scaler)\n",
    "\n",
    "def get_top_3_accuracy(top_3_test_preds, y_test):\n",
    "    successes = 0\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_test[i] in top_3_test_preds[i][0]:\n",
    "            successes += 1\n",
    "    return float(successes)/ y_test.shape[0]\n",
    "\n",
    "def get_core_metrics(features_df, preds_patch, enable_dlbcl_classification=False):\n",
    "    features_df[\"preds_patch\"] = preds_patch\n",
    "    y_core = features_df.groupby(\"patient_id\")[\"label\"].agg(pd.Series.mode)\n",
    "    if enable_dlbcl_classification:\n",
    "        y_core = y_core.apply(lambda l : 0 if l == 0 else 1)\n",
    "    preds_core = features_df.groupby(\"patient_id\")[\"preds_patch\"].agg(lambda x: pd.Series.mode(x)[0])\n",
    "    accuracy = compute_accuracy(preds_core, y_core)\n",
    "    return (y_core, preds_core, accuracy)\n",
    "\n",
    "def get_sgd_pred_probs(model, X):\n",
    "    return model.predict_proba(X)\n",
    "\n",
    "def get_lgb_pred_probs(model, X):\n",
    "    return softmax(model.predict(X))\n",
    "\n",
    "def get_mean_probability(pred_probs):\n",
    "    return np.argmax(pd.Series.mean(pred_probs, axis=0))\n",
    "\n",
    "def get_core_metrics_mean(features_df, pred_probs):\n",
    "    classes = range(num_classes)\n",
    "    pred_probs_df = pd.DataFrame(pred_probs, columns = classes)\n",
    "    pred_probs_df[\"patient_id\"] = features_df[\"patient_id\"]\n",
    "    pred_prob_df_aggregated = pred_probs_df.groupby(\"patient_id\").aggregate(pd.DataFrame.mean)\n",
    "    y_core = features_df.groupby(\"patient_id\")[\"label\"].agg(pd.Series.mode)\n",
    "    preds_core = pred_prob_df_aggregated.idxmax(axis=1)\n",
    "    accuracy = compute_accuracy(preds_core, y_core)\n",
    "    return (y_core, preds_core, accuracy)\n",
    "\n",
    "def accuracy_eval_metric(preds, dtrain):\n",
    "    labels = dtrain.label\n",
    "    preds = preds.reshape(num_classes, -1).T\n",
    "    preds = preds.argmax(axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return 'accuracy', accuracy, False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
